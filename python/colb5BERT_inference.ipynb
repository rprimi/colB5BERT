{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rprimi/colB5BERT/blob/main/python/colb5BERT_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijk96nJ77H3t"
      },
      "source": [
        "### **colB5BERT:** Inference and scoring B5\n",
        "\n",
        "Solução Baseada no notebook do Pedro Genco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1wco2iUqepZ",
        "outputId": "a1b8084c-5286-4472-fbc5-d4e24d5ab55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZUio6VJkQfQ"
      },
      "outputs": [],
      "source": [
        "!pip3 install transformers hnswlib evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8evBd6sMsqT",
        "outputId": "1c16007e-2bd4-4ace-b18d-88910e236ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'colB5BERT'...\n",
            "remote: Enumerating objects: 294, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 294 (delta 73), reused 18 (delta 18), pack-reused 196\u001b[K\n",
            "Receiving objects: 100% (294/294), 32.73 MiB | 42.53 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "/content/colB5BERT\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rprimi/colB5BERT.git\n",
        "\n",
        "%cd /content/colB5BERT\n",
        "!git pull\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wIOgkGQmkk-5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import json\n",
        "\n",
        "import hnswlib\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from collections import defaultdict\n",
        "from evaluate import load\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BatchEncoding\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup, AdamW\n",
        "\n",
        "import textwrap\n",
        "import pickle\n",
        "import h5py\n",
        "import logging\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import torch\n",
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# sys.path.append('/content/colB5BERT/python/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAqaTuEMVTsp",
        "outputId": "0187ffb0-713b-4225-ccbb-d3272a858746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 28 19:49:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    42W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fT5wqWymwppW",
        "outputId": "d83858c8-ed0a-4ee2-e9c0-8f7faecd22cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          coditem domain  pole  \\\n",
              "0         bfi2_47      A     0   \n",
              "1         bfi2_47      A     0   \n",
              "2         bfi2_47      A     0   \n",
              "3         bfi2_47      A     0   \n",
              "4         bfi2_47      A     0   \n",
              "...           ...    ...   ...   \n",
              "633094  STA_STR10      N     0   \n",
              "633095  STA_STR10      N     0   \n",
              "633096  STA_STR10      N     0   \n",
              "633097  STA_STR10      N     0   \n",
              "633098  STA_STR10      N     0   \n",
              "\n",
              "                                             item_pt_text    id  id_divisao  \\\n",
              "0       Posso ser indiferente, frio e distante dos outros  1008           1   \n",
              "1       Posso ser indiferente, frio e distante dos outros  1008           2   \n",
              "2       Posso ser indiferente, frio e distante dos outros  1008           3   \n",
              "3       Posso ser indiferente, frio e distante dos outros  1008           4   \n",
              "4       Posso ser indiferente, frio e distante dos outros  1008           5   \n",
              "...                                                   ...   ...         ...   \n",
              "633094  Fico ansioso(a)/aflito(a) quando o período de ...   999           6   \n",
              "633095  Fico ansioso(a)/aflito(a) quando o período de ...   999           7   \n",
              "633096  Fico ansioso(a)/aflito(a) quando o período de ...   999           8   \n",
              "633097  Fico ansioso(a)/aflito(a) quando o período de ...   999           9   \n",
              "633098  Fico ansioso(a)/aflito(a) quando o período de ...   999          10   \n",
              "\n",
              "                                           texto_dividido  postive_ex  \n",
              "0       Cada um com seu poder $LAUGH$ saudades < $NUMB...           0  \n",
              "1       , recados por amigos , cartas , pombos correio...           0  \n",
              "2       difícil $LAUGH$ de um lado uma das primeiras a...           0  \n",
              "3       melhor te espera PAR muita paz e luz meu amigo...           0  \n",
              "4       fale bem neste dia muito especial quero te des...           0  \n",
              "...                                                   ...         ...  \n",
              "633094  amo muito ! < $NUMBER$ < $NUMBER$ \"\"\"\" Fique p...           0  \n",
              "633095  pai ! Feliz aniversário ! < $NUMBER$ < $NUMBER...           0  \n",
              "633096  rei do $NAME$ Club de $NAME$ Oeste : $NAME$ $N...           0  \n",
              "633097  todo tipo de público . A realização do projeto...           0  \n",
              "633098  sobre sua vida , e as mais recentes ajudam a c...           0  \n",
              "\n",
              "[633099 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59111fc0-a984-489b-9c3c-0cb96b97a7ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coditem</th>\n",
              "      <th>domain</th>\n",
              "      <th>pole</th>\n",
              "      <th>item_pt_text</th>\n",
              "      <th>id</th>\n",
              "      <th>id_divisao</th>\n",
              "      <th>texto_dividido</th>\n",
              "      <th>postive_ex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bfi2_47</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>Posso ser indiferente, frio e distante dos outros</td>\n",
              "      <td>1008</td>\n",
              "      <td>1</td>\n",
              "      <td>Cada um com seu poder $LAUGH$ saudades &lt; $NUMB...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bfi2_47</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>Posso ser indiferente, frio e distante dos outros</td>\n",
              "      <td>1008</td>\n",
              "      <td>2</td>\n",
              "      <td>, recados por amigos , cartas , pombos correio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bfi2_47</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>Posso ser indiferente, frio e distante dos outros</td>\n",
              "      <td>1008</td>\n",
              "      <td>3</td>\n",
              "      <td>difícil $LAUGH$ de um lado uma das primeiras a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bfi2_47</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>Posso ser indiferente, frio e distante dos outros</td>\n",
              "      <td>1008</td>\n",
              "      <td>4</td>\n",
              "      <td>melhor te espera PAR muita paz e luz meu amigo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bfi2_47</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>Posso ser indiferente, frio e distante dos outros</td>\n",
              "      <td>1008</td>\n",
              "      <td>5</td>\n",
              "      <td>fale bem neste dia muito especial quero te des...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633094</th>\n",
              "      <td>STA_STR10</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>Fico ansioso(a)/aflito(a) quando o período de ...</td>\n",
              "      <td>999</td>\n",
              "      <td>6</td>\n",
              "      <td>amo muito ! &lt; $NUMBER$ &lt; $NUMBER$ \"\"\"\" Fique p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633095</th>\n",
              "      <td>STA_STR10</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>Fico ansioso(a)/aflito(a) quando o período de ...</td>\n",
              "      <td>999</td>\n",
              "      <td>7</td>\n",
              "      <td>pai ! Feliz aniversário ! &lt; $NUMBER$ &lt; $NUMBER...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633096</th>\n",
              "      <td>STA_STR10</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>Fico ansioso(a)/aflito(a) quando o período de ...</td>\n",
              "      <td>999</td>\n",
              "      <td>8</td>\n",
              "      <td>rei do $NAME$ Club de $NAME$ Oeste : $NAME$ $N...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633097</th>\n",
              "      <td>STA_STR10</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>Fico ansioso(a)/aflito(a) quando o período de ...</td>\n",
              "      <td>999</td>\n",
              "      <td>9</td>\n",
              "      <td>todo tipo de público . A realização do projeto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633098</th>\n",
              "      <td>STA_STR10</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>Fico ansioso(a)/aflito(a) quando o período de ...</td>\n",
              "      <td>999</td>\n",
              "      <td>10</td>\n",
              "      <td>sobre sua vida , e as mais recentes ajudam a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>633099 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59111fc0-a984-489b-9c3c-0cb96b97a7ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59111fc0-a984-489b-9c3c-0cb96b97a7ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59111fc0-a984-489b-9c3c-0cb96b97a7ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/colB5BERT/dataset_test_positive.tsv', sep='\\t')\n",
        "\n",
        "print(f'Test dataset: {len(df_test)}')\n",
        "# Sample data to test the pipeline\n",
        "df_test = df_test.sample(n = 50)\n",
        "\n",
        "\n",
        "dataset_test = pd.read_csv('/content/drive/MyDrive/colB5BERT/dataset_test.tsv', sep='\\t')\n",
        "\n",
        "print(f'Dataset test: {len(dataset_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class `Encoder` is a subclass of PyTorch's `nn.Module`, which is used to construct neural network architectures. This class is intended to serve as an encoder which takes an input (`x`), processes it using a base model (like a pretrained transformer), and returns the resulting embeddings. Here's a breakdown of the steps:\n",
        "\n",
        "1. `__init__(self, base_model, use_cls = False)`: The constructor method. When an object of class `Encoder` is created, it needs to be provided with a `base_model` (a pre-trained model such as BERT, GPT, etc.) and an optional parameter `use_cls`. The `use_cls` parameter is a boolean flag indicating whether to use the output embedding of the [CLS] token or to average the output embeddings of all tokens.\n",
        "\n",
        "2. `forward(self, x)`: The method that's called during the forward pass of the model. The input `x` is expected to be a dictionary containing the input IDs of the tokens and the attention mask.\n",
        "\n",
        "3. `embeddings = self.base_model(**x)`: This line feeds the input `x` to the `base_model` and retrieves the output. The output is a tuple where the first element is the output from the transformer's encoder, i.e., the embeddings for each token in the input sequence.\n",
        "\n",
        "4. `if self.use_cls:`: This is a conditional statement checking whether `use_cls` was set to `True` or `False`.\n",
        "\n",
        "    - If `use_cls` is `True`, then `embeddings = embeddings[0][:, 0, :]` selects the embeddings of the [CLS] token. In the output of transformer models, the first token is usually the [CLS] token, so this line is getting the embeddings of that token.\n",
        "\n",
        "    - If `use_cls` is `False`, then the `else` block is executed:\n",
        "        - `embeddings = embeddings[0]` : Here, it is simply getting all the embeddings from the transformer's output.\n",
        "        \n",
        "        - `attention_mask = x[\"attention_mask\"]` : Extracts the attention mask from the input `x`. The attention mask is used to avoid performing attention on padding token indices.\n",
        "\n",
        "        - `input_mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()`: The attention mask is expanded to match the dimensions of `embeddings`. The mask is also converted to float type as the embeddings are floats.\n",
        "        \n",
        "        - `embeddings = torch.sum(embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)`: This line calculates the sum of the embeddings of all tokens in each sequence, but only for tokens that aren't padding (as indicated by the attention mask). It then divides this sum by the number of non-padding tokens in each sequence to calculate the average. The `torch.clamp` is used to prevent division by zero in case a sequence contains only padding tokens.\n",
        "\n",
        "5. `return embeddings`: The method finally returns the computed embeddings.\n",
        "\n",
        "So, in summary, this module can provide two kinds of embeddings: (1) Embedding of [CLS] token when `use_cls=True`, which is commonly used for sequence-level classification tasks; and (2) Average of all the non-padding token embeddings when `use_cls=False`, providing a single vector that takes into account all the tokens in the sequence."
      ],
      "metadata": {
        "id": "bQqZYBi-bkFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, base_model, use_cls = False):\n",
        "    super().__init__()\n",
        "    self.base_model = base_model\n",
        "    self.use_cls = use_cls\n",
        "\n",
        "  def forward(self, x):\n",
        "    embeddings = self.base_model(**x)\n",
        "\n",
        "    if self.use_cls:\n",
        "      embeddings = embeddings[0][:, 0, :]\n",
        "    else:\n",
        "      embeddings = embeddings[0] #First element of model_output contains all token embeddings\n",
        "      attention_mask = x[\"attention_mask\"]\n",
        "      input_mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
        "      embeddings = torch.sum(embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "GHJyPXGMivnW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"use_cls\": False,\n",
        "    \"similarity_function\": \"dot\",\n",
        "    \"model_name\": 'neuralmind/bert-base-portuguese-cased',\n",
        "}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(params[\"model_name\"])\n",
        "model_query = AutoModel.from_pretrained(params[\"model_name\"])\n",
        "model_doc = AutoModel.from_pretrained(params[\"model_name\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-7iGpkAwYCJ",
        "outputId": "e7371174-81fc-4135-b501-d160d1fb830f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_query = Encoder(model_query, False)\n",
        "encoder_doc = Encoder(model_doc, False)\n",
        "\n",
        "\n",
        "#map_location=torch.device('cpu')\n",
        "encoder_query.load_state_dict(torch.load('/content/drive/MyDrive/colB5BERT/model_query_epoch_0.pt'))\n",
        "encoder_doc.load_state_dict(torch.load('/content/drive/MyDrive/colB5BERT/model_doc_epoch_0.pt'))\n",
        "\n",
        "\n",
        "#for k,v in ckpt.items():\n",
        "#    restored_ckpt[k.replace('_orig_mod.', '')] = v\n",
        "\n",
        "#model_query = torch.compile(model_query)\n",
        "#model_query.load_state_dict(restored_ckpt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooLQSQjMbIW2",
        "outputId": "fc0bd53b-9826-46bb-c751-5497d886befc"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QueriesDataset(Dataset):\n",
        "  def __init__(self, queries, tokenizer):\n",
        "    self.queries = queries\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.queries)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    tokenized_query = self.tokenizer(\n",
        "        self.queries[idx],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=32,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    output = {\n",
        "        \"input_ids\": tokenized_query[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": tokenized_query[\"attention_mask\"].squeeze()\n",
        "    }\n",
        "    return output\n",
        "\n",
        "class DocumentsDataset(Dataset):\n",
        "  def __init__(self, relevant_documents,  tokenizer):\n",
        "    self.relevant_documents = relevant_documents\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.relevant_documents)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    tokenized_doc = self.tokenizer(\n",
        "        self.relevant_documents[idx],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    sample = {\n",
        "        \"relevant_input_ids\": tokenized_doc[\"input_ids\"].squeeze(),\n",
        "        \"relevant_attention_mask\": tokenized_doc[\"attention_mask\"].squeeze()\n",
        "    }\n",
        "    return sample\n"
      ],
      "metadata": {
        "id": "h1WbwYiWOVJS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_dataset_eval = QueriesDataset(queries = list(dataset_test['item_pt_text']), tokenizer = tokenizer)\n",
        "doc_datasets_eval = DocumentsDataset(list(dataset_test['texto_dividido']), tokenizer)"
      ],
      "metadata": {
        "id": "QhKrjgFhN55p"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_query_dataloader = DataLoader(query_dataset_eval, batch_size = 500, shuffle=False)\n",
        "eval_doc_dataloader = DataLoader(doc_datasets_eval, batch_size = 500, shuffle=False)"
      ],
      "metadata": {
        "id": "ihe0Ag5bGul2"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_b5(eval_dataloader_query, eval_dataloader_doc, model_query, model_doc, device):\n",
        "\n",
        "  model_query.eval()\n",
        "  model_doc.eval()\n",
        "  outputs_scores=[]\n",
        "\n",
        "  for query_batch, doc_batch in tqdm(zip(eval_dataloader_query, eval_dataloader_doc), total=len(eval_dataloader_query), desc='Scoring Queries'):\n",
        "    with torch.no_grad():\n",
        "      query_input = {\n",
        "          \"input_ids\": query_batch[\"input_ids\"].to(device),\n",
        "          \"attention_mask\": query_batch[\"attention_mask\"].to(device)\n",
        "      }\n",
        "      query_emb = model_query(query_input)\n",
        "\n",
        "      relevant_input = {\n",
        "          \"input_ids\": doc_batch[\"relevant_input_ids\"].to(device),\n",
        "          \"attention_mask\": doc_batch[\"relevant_attention_mask\"].to(device)\n",
        "      }\n",
        "\n",
        "      relevant_embeddings = model_doc(relevant_input)\n",
        "\n",
        "      ## Split in two parts: dot product of query and relevant, and dot product of query and not rel\n",
        "\n",
        "      sim = torch.matmul(query_emb, relevant_embeddings.T) # B, H x H, B = B, B\n",
        "      #print(sim)\n",
        "      scores_sim = torch.diagonal(sim, 0) # B,\n",
        "      #print(scores_sim)\n",
        "      outputs_scores.append(scores_sim.cpu().numpy())\n",
        "\n",
        "  return(outputs_scores)\n",
        "\n",
        "  #print(f\"Eval loss: {loss_val / len(eval_dataloader_query)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IfwB_MwNCYQi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "import gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "encoder_doc = encoder_doc.to(device)\n",
        "encoder_query = encoder_query.to(device)\n",
        "\n",
        "b5_scores = score_b5(eval_query_dataloader, eval_doc_dataloader, encoder_query, encoder_doc, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "34a3ff8248fb48848d680df0d4882055",
            "1d585e516c144ee687a7ce3e46caf86b",
            "8677058b8cf74c8180239cb7698a0574",
            "c4cb8ced051a490f87f98de0b36a4f0d",
            "23a833ed76764bba8b4317066e5e5049",
            "a1c6c8b43ae7434eabf16c1c160388cd",
            "fb9d4acc977f491c85acaa34c2ddd4e2",
            "ba02d0b1f2c542d59260aaa52c3ad55a",
            "70cf1f94f1624a5a939536612ede4de0",
            "bb8c0ce3fd534927a70b4787b9137f51",
            "fe45fd197681424088bbd33f6f4050f5"
          ]
        },
        "id": "FK0m1iU6xF_c",
        "outputId": "203b2e49-75e3-44f3-8298-d728c2e44b8a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Scoring Queries:   0%|          | 0/1267 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a3ff8248fb48848d680df0d4882055"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(b5_scores)\n",
        "b5_scores[0:3]\n",
        "\n",
        "b5_scores2 = np.concatenate(b5_scores, axis=0)\n",
        "b5_scores[0:3]\n",
        "b5_scores2[500:502]\n",
        "\n",
        "print(b5_scores2)\n",
        "b5_scores =\n",
        "len(dataset_test)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/colB5BERT/b5_scores2.pkl\", \"wb\") as file:\n",
        "    pickle.dump(b5_scores2 , file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9DkYFyKA1VE",
        "outputId": "ed80900f-1b42-4dc5-a7ed-29cedf182826"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.0000343,  6.8716364,  5.893053 , ...,  2.5232058, -1.6123338,\n",
              "       -1.9377005], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPN8yO1Y5oA8omWDcxgpJFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34a3ff8248fb48848d680df0d4882055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d585e516c144ee687a7ce3e46caf86b",
              "IPY_MODEL_8677058b8cf74c8180239cb7698a0574",
              "IPY_MODEL_c4cb8ced051a490f87f98de0b36a4f0d"
            ],
            "layout": "IPY_MODEL_23a833ed76764bba8b4317066e5e5049"
          }
        },
        "1d585e516c144ee687a7ce3e46caf86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c6c8b43ae7434eabf16c1c160388cd",
            "placeholder": "​",
            "style": "IPY_MODEL_fb9d4acc977f491c85acaa34c2ddd4e2",
            "value": "Scoring Queries: 100%"
          }
        },
        "8677058b8cf74c8180239cb7698a0574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba02d0b1f2c542d59260aaa52c3ad55a",
            "max": 1267,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70cf1f94f1624a5a939536612ede4de0",
            "value": 1267
          }
        },
        "c4cb8ced051a490f87f98de0b36a4f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8c0ce3fd534927a70b4787b9137f51",
            "placeholder": "​",
            "style": "IPY_MODEL_fe45fd197681424088bbd33f6f4050f5",
            "value": " 1267/1267 [1:25:25&lt;00:00,  3.09s/it]"
          }
        },
        "23a833ed76764bba8b4317066e5e5049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c6c8b43ae7434eabf16c1c160388cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9d4acc977f491c85acaa34c2ddd4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba02d0b1f2c542d59260aaa52c3ad55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70cf1f94f1624a5a939536612ede4de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb8c0ce3fd534927a70b4787b9137f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe45fd197681424088bbd33f6f4050f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}