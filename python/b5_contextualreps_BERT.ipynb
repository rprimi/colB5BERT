{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rprimi/colB5BERT/blob/main/python/b5_contextualreps_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8TP1m0F_Y6-H"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Ricardo Primi adapted from modules from Christopher Potts, CS224u, Stanford, Spring 2021\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnEbhqVTY6-J"
      },
      "source": [
        "### General set-up\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z1wco2iUqepZ",
        "outputId": "d0b738ad-50ab-49c4-a506-3ab04ec8565a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZUio6VJkQfQ"
      },
      "outputs": [],
      "source": [
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rprimi/colB5BERT.git\n",
        "\n",
        "%cd /content/colB5BERT\n",
        "!git pull\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8evBd6sMsqT",
        "outputId": "2b5c5048-ba61-4f23-fca8-4faa6ec904f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'colB5BERT'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 123 (delta 69), reused 48 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (123/123), 11.94 MiB | 16.84 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "/content/colB5BERT\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FneXYJMlY6-K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import RobertaModel, RobertaTokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOgZt0MKWbOI"
      },
      "source": [
        "Modules `vsm`, `utils` and `sst` are from Stanford's CS224u https://github.com/cgpotts/cs224u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wIOgkGQmkk-5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/colB5BERT/python/')\n",
        "\n",
        "import utils\n",
        "import vsm\n",
        "import sst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DSpFAHTsFF-"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "   dev = \"cuda:0\"\n",
        "else:\n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o0iX5kbasHZd",
        "outputId": "1df9dfe9-1c31-477d-e87a-88c82c1043ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 14 14:43:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    45W / 400W |      3MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "JAqaTuEMVTsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dTrPrG2kdCz"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pboznS998H17",
        "outputId": "906ef81f-b9af-44d8-eeb8-4a4ca7277628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11537 entries, 0 to 11536\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              11537 non-null  int64 \n",
            " 1   id_divisao      11537 non-null  int64 \n",
            " 2   texto_dividido  11537 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 270.5+ KB\n"
          ]
        }
      ],
      "source": [
        "b5_data = pd.read_csv('/content/colB5BERT/data/db_textos.splitted.csv', sep=';')\n",
        "b5_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b5_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZX_oY24kO-Tg",
        "outputId": "3dd54f20-df64-4392-a403-23495756ff89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  id_divisao                                     texto_dividido\n",
              "0      100           1  ajudando porque a zuzu é um amor e tem a voz f...\n",
              "1      100           2  vai ter share sim e se reclamar dou share mais...\n",
              "2      100           3  quanto parece , A , $NUMBER$ . MvC $NUMBER$ CL...\n",
              "3      100           4  $NUMBER$ jeitos de dar entry então é só sucess...\n",
              "4      100           5  quiser se vira Esse livro é de co-autoria de $...\n",
              "...    ...         ...                                                ...\n",
              "11532  999           6  amo muito ! < $NUMBER$ < $NUMBER$ \" Fique por ...\n",
              "11533  999           7  pai ! Feliz aniversário ! < $NUMBER$ < $NUMBER...\n",
              "11534  999           8  rei do $NAME$ Club de $NAME$ Oeste : $NAME$ $N...\n",
              "11535  999           9  todo tipo de público . A realização do projeto...\n",
              "11536  999          10  sobre sua vida , e as mais recentes ajudam a c...\n",
              "\n",
              "[11537 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af2cc12b-28fb-4a1c-ac8f-b9b0a1372d60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>id_divisao</th>\n",
              "      <th>texto_dividido</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>ajudando porque a zuzu é um amor e tem a voz f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>vai ter share sim e se reclamar dou share mais...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>quanto parece , A , $NUMBER$ . MvC $NUMBER$ CL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>$NUMBER$ jeitos de dar entry então é só sucess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>quiser se vira Esse livro é de co-autoria de $...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11532</th>\n",
              "      <td>999</td>\n",
              "      <td>6</td>\n",
              "      <td>amo muito ! &lt; $NUMBER$ &lt; $NUMBER$ \" Fique por ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11533</th>\n",
              "      <td>999</td>\n",
              "      <td>7</td>\n",
              "      <td>pai ! Feliz aniversário ! &lt; $NUMBER$ &lt; $NUMBER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11534</th>\n",
              "      <td>999</td>\n",
              "      <td>8</td>\n",
              "      <td>rei do $NAME$ Club de $NAME$ Oeste : $NAME$ $N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11535</th>\n",
              "      <td>999</td>\n",
              "      <td>9</td>\n",
              "      <td>todo tipo de público . A realização do projeto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11536</th>\n",
              "      <td>999</td>\n",
              "      <td>10</td>\n",
              "      <td>sobre sua vida , e as mais recentes ajudam a c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11537 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af2cc12b-28fb-4a1c-ac8f-b9b0a1372d60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af2cc12b-28fb-4a1c-ac8f-b9b0a1372d60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af2cc12b-28fb-4a1c-ac8f-b9b0a1372d60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "base_itens_b5 = pd.read_excel('/content/colB5BERT/data/base_itens.xlsx')\n",
        "\n",
        "\n",
        "base_itens_b5\n",
        "base_itens_b5.info()\n",
        "# base_itens_b5['item_pt_text'].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOaFKAKmhp5m",
        "outputId": "b9f9e05c-5fe9-4933-cec4-640fb080788c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 415 entries, 0 to 414\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   ord0_index    415 non-null    int64  \n",
            " 1   test          415 non-null    object \n",
            " 2   coditem       415 non-null    object \n",
            " 3   item_pt_text  415 non-null    object \n",
            " 4   item_en_text  415 non-null    object \n",
            " 5   domain        413 non-null    object \n",
            " 6   facet         413 non-null    object \n",
            " 7   pole          415 non-null    int64  \n",
            " 8   seman_pairs   273 non-null    float64\n",
            "dtypes: float64(1), int64(2), object(6)\n",
            "memory usage: 29.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS59UBqrY6-L"
      },
      "source": [
        "### Loading Transformer models\n",
        "Specify a model, a tokenizer, and load a model pretrained weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6f6UXqGY6-L"
      },
      "outputs": [],
      "source": [
        "bert_weights_name = 'neuralmind/bert-base-portuguese-cased'\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
        "bert_model = BertModel.from_pretrained(bert_weights_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHrst3TZY6-M"
      },
      "source": [
        "### The basics of tokenizing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOg05YkzY6-M"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_cell(df, row, column, wrap_length=80):\n",
        "    if row < len(df) and column in df.columns:\n",
        "        text = df.loc[row, column]\n",
        "        print('\\n'.join(textwrap.wrap(text, width=wrap_length)))\n",
        "    else:\n",
        "        print(\"Invalid row or column\")\n",
        "\n",
        "print_cell(b5_data, 3, 'texto_dividido')\n",
        "\n",
        "ex_ids = bert_tokenizer.encode(b5_data.loc[3, 'texto_dividido'], add_special_tokens=True)\n",
        "bert_tokenizer.convert_ids_to_tokens(ex_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDRVTaxRY6-P"
      },
      "source": [
        "### Getting BERT embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV8TNuFDY6-P"
      },
      "source": [
        "To obtain the representations for a batch of examples, we use the `forward` method of the model, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9BLypVjY6-P"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert_model(torch.tensor([ex_ids]), output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_texts(texts):\n",
        "    # Tokenize each text and convert to input IDs\n",
        "    input_ids = [bert_tokenizer.encode(text, add_special_tokens=True) for text in texts]\n",
        "    return input_ids\n",
        "\n",
        "\n",
        "def tokenize_texts(bert_tokenizer, texts):\n",
        "    tokenized_texts = []\n",
        "    for text in texts:\n",
        "        encoded_text = bert_tokenizer.encode(text, add_special_tokens=True)\n",
        "        # truncate the encoded text to the first 512 tokens\n",
        "        encoded_text = encoded_text[:512]\n",
        "        # encoded_text = encoded_text\n",
        "        tokenized_texts.append(encoded_text)\n",
        "    return tokenized_texts\n",
        "\n"
      ],
      "metadata": {
        "id": "r11vxToiVrfP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize_texts(ex_of_texts)\n",
        "ex_of_texts = b5_data.iloc[[0, 1, 2, 3], b5_data.columns.get_loc('texto_dividido')].tolist()\n",
        "lengths = [len(sublist) for sublist in tokenize_texts(bert_tokenizer, ex_of_texts)]\n",
        "\n",
        "print(lengths)  # Output: [3, 2, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2ddFICvXD7F",
        "outputId": "081ed75e-be17-4b9a-cafa-75298797954a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[512, 512, 477, 512]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def get_bert_embeddings(bert_model, examples, layers):\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    bert_model = bert_model.to(device)\n",
        "\n",
        "    embeddings = {layer: [] for layer in layers}\n",
        "    for ex_ids in examples:\n",
        "        # Convert data to tensor and move to GPU\n",
        "        ex_ids_tensor = torch.tensor([ex_ids]).to(device)\n",
        "        with torch.no_grad():\n",
        "            # Output includes 'last_hidden_state', 'pooler_output', 'hidden_states'\n",
        "            output = bert_model(ex_ids_tensor, output_hidden_states=True)\n",
        "            hidden_states = output.hidden_states\n",
        "            for layer in layers:\n",
        "                # Verify layer index is valid\n",
        "                if layer < 0 or layer >= len(hidden_states):\n",
        "                    print(f\"Invalid layer {layer}\")\n",
        "                else:\n",
        "                    # Hidden states is a tuple. Indexing into it gives a tensor of shape\n",
        "                    # (batch_size, sequence_length, hidden_size). Since batch_size is 1,\n",
        "                    # we remove the batch dimension.\n",
        "                    layer_output = hidden_states[layer].squeeze(0)\n",
        "                    # Convert back to CPU for further processing or storage\n",
        "                    embeddings[layer].append(layer_output.to('cpu'))\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "6uybcKQ_VFQO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [6, 9, 11, 12]  # Specify the layers you want\n",
        "embeddings = get_bert_embeddings(bert_model, tokenize_texts(bert_tokenizer, ex_of_texts), layers)\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(embeddings )\n",
        "\n",
        "\n",
        "dir(embeddings)\n",
        "vars(embeddings)\n",
        "import inspect\n",
        "inspect.getmembers(embeddings)\n",
        "\n",
        "pprint.pprint(embeddings[9])\n",
        "len(embeddings[9])\n",
        "len(embeddings[9][2])\n",
        "pprint.pprint(embeddings[9][2])\n",
        "x = embeddings[9][2]\n",
        "x.shape\n",
        "\n",
        "dimensions = [len(inner_list) for inner_list in embeddings[9][0]]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpAtS9ZIVH8j",
        "outputId": "aa9383f4-8e8a-4eae-815a-c8deab1863a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([477, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finaly getting the embeddings"
      ],
      "metadata": {
        "id": "k4pHrJ-3Du2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the layers you want\n",
        "layers = [ 6, 9, 11, 12]\n",
        "len(b5_data['texto_dividido'].tolist())\n",
        "\n",
        "embeddings_posts = get_bert_embeddings(bert_model, tokenize_texts(bert_tokenizer, b5_data['texto_dividido'].tolist()), layers)\n",
        "embeddings_itens = get_bert_embeddings(bert_model, tokenize_texts(bert_tokenizer, base_itens_b5['item_pt_text'].tolist()), layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "l50Z1laf-fof"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def save_embeddings_to_disk(embeddings, filename):\n",
        "    # Convert tensors to numpy arrays and store them in the same structure\n",
        "    numpy_embeddings = {str(layer): [t.numpy() for t in tensors] for layer, tensors in embeddings.items()}\n",
        "\n",
        "    # Use numpy's savez function to store the dictionary\n",
        "    # We use ** to unpack the dictionary into keyword arguments\n",
        "    np.savez(filename, **numpy_embeddings)\n",
        "\n",
        "def load_embeddings_from_disk(filename):\n",
        "    with np.load(filename) as data:\n",
        "        embeddings = {layer: data[layer] for layer in data.files}\n",
        "    return embeddings\n",
        "\n",
        "filename=\"/content/drive/MyDrive/colB5BERT/embeddings_itens\"\n",
        "\n",
        "save_embeddings_to_disk(embeddings=embeddings_itens, filename=filename)\n",
        "\n",
        "filename=\"/content/drive/MyDrive/colB5BERT/embeddings_posts\"\n",
        "save_embeddings_to_disk(embeddings=embeddings_posts, filename=filename)\n"
      ],
      "metadata": {
        "id": "xzFTFdsti-2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving embeddings to disk is a common task when working with models like BERT, because it allows you to avoid recomputing the embeddings for the same input multiple times. There are several ways to store embeddings, but two popular methods are:\n",
        "\n",
        "1. Saving as numpy arrays using np.save or np.savez (for multiple arrays at once).\n",
        "2. Saving as a pickle file, which is a Python-specific binary format.\n",
        "\n",
        "In your case, since you have a dictionary where each entry is a list of PyTorch tensors, you can first convert your tensors to numpy arrays, and then use one of these methods to store them. Here is an example of how you can do this with numpy:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def save_embeddings_to_disk(embeddings, filename):\n",
        "    # Convert tensors to numpy arrays and store them in the same structure\n",
        "    numpy_embeddings = {layer: [t.numpy() for t in tensors] for layer, tensors in embeddings.items()}\n",
        "\n",
        "    # Use numpy's savez function to store the dictionary\n",
        "    # We use ** to unpack the dictionary into keyword arguments\n",
        "    np.savez(filename, **numpy_embeddings)\n",
        "```\n",
        "\n",
        "Then, you can load your embeddings back with:\n",
        "\n",
        "```python\n",
        "def load_embeddings_from_disk(filename):\n",
        "    with np.load(filename) as data:\n",
        "        embeddings = {layer: data[layer] for layer in data.files}\n",
        "    return embeddings\n",
        "```\n",
        "\n",
        "This will give you a dictionary where the keys are the layers, and the values are lists of numpy arrays.\n",
        "\n",
        "Please note that you may have to handle large files depending on the size of your embeddings and the number of examples. This can be managed by saving in chunks or using compressed formats if necessary."
      ],
      "metadata": {
        "id": "HhllYoievKsa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dAjiBuZ9u_Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings is a dict of `layers` keys. Each component of one key is composed of `batch size` elments of a tensor with size `num_of_tokens X embedding_dim`.\n",
        "\n",
        "The final structure is `layers X batch size X num_of_tokens X embedding_dim`"
      ],
      "metadata": {
        "id": "t4aDJx91AehR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how many posts\n",
        "len(embeddings_posts[6])\n",
        "embeddings_posts[6]\n",
        "\n",
        "# what is the first element ? of the first post\n",
        "type(embeddings_posts[6][0])\n",
        "\n",
        "# what is the dimension\n",
        "embeddings_posts[6][0].shape\n",
        "\n",
        "\n",
        "\n",
        "# how many posts\n",
        "len(embeddings_itens[6])\n",
        "\n",
        "# what is the first element ? of the first post\n",
        "type(embeddings_itens[6][0])\n",
        "\n",
        "# what is the dimension\n",
        "embeddings_itens[6][0].shape\n",
        "\n",
        "type(embeddings_itens[6])"
      ],
      "metadata": {
        "id": "H1d5NWmsDnVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have a list of A of i elements. Each elment is a torch tensor of n_tokens1 X 768 (dim of embedings) . Then I have a list of B of p elements. Each elment is a torch tensor of n_tokens2 X 768 (dim of embedings). I want to claculate the cosine similarity between embedding vectors n_tokens1 with n_tokens2. I want the result to be a list of i elements by p elments of matrices n_tokens1 X n_tokens2 containing the cossine similarities. Please creeate a code in python using efficient vectorized operations"
      ],
      "metadata": {
        "id": "dOlXOw7yG7mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_cosine_similarity(list_A, list_B):\n",
        "    result = []\n",
        "    for tensor_A in list_A:\n",
        "        for tensor_B in list_B:\n",
        "            # Expand dimensions so that shapes are [n_tokens_A, 1, 768] and [1, n_tokens_B, 768]\n",
        "            tensor_A_exp = tensor_A.unsqueeze(1)\n",
        "            tensor_B_exp = tensor_B.unsqueeze(0)\n",
        "            # Compute cosine similarity\n",
        "            similarity = cosine_similarity(tensor_A_exp, tensor_B_exp, dim=-1)\n",
        "            result.append(similarity)\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(list_A, list_B, topk=5):\n",
        "    result = []\n",
        "    for tensor_A in list_A:\n",
        "        similarities = []\n",
        "        for tensor_B in list_B:\n",
        "            # Expand dimensions so that shapes are [n_tokens_A, 1, 768] and [1, n_tokens_B, 768]\n",
        "            tensor_A_exp = tensor_A.unsqueeze(1)\n",
        "            tensor_B_exp = tensor_B.unsqueeze(0)\n",
        "            # Compute cosine similarity\n",
        "            similarity = torch.nn.functional.cosine_similarity(tensor_A_exp, tensor_B_exp, dim=-1)\n",
        "            similarities.append(similarity)\n",
        "        # Concatenate all similarity scores and find the topk\n",
        "        similarities = torch.cat(similarities, dim=-1)\n",
        "        topk_values, topk_indices = torch.topk(similarities, topk, dim=-1)\n",
        "        result.append((topk_values, topk_indices))\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(list_A, list_B, topk=5, batch_size=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    result = []\n",
        "\n",
        "    # Move tensors to GPU\n",
        "    list_A = [tensor.to(device) for tensor in list_A]\n",
        "    list_B = [tensor.to(device) for tensor in list_B]\n",
        "\n",
        "    # Process batch_size tensor_A at a time\n",
        "    for i in range(0, len(list_A), batch_size):\n",
        "        batch_A = list_A[i:i+batch_size]\n",
        "        batch_A = torch.stack(batch_A).unsqueeze(2)  # [batch_size, n_tokens_A, 1, 768]\n",
        "        similarities = []\n",
        "\n",
        "        for tensor_B in list_B:\n",
        "            tensor_B = tensor_B.unsqueeze(0).unsqueeze(0)  # [1, 1, n_tokens_B, 768]\n",
        "            similarity = torch.nn.functional.cosine_similarity(batch_A, tensor_B, dim=-1)  # [batch_size, n_tokens_A, n_tokens_B]\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        similarities = torch.cat(similarities, dim=-1)  # [batch_size, n_tokens_A, n_tokens_B*len(list_B)]\n",
        "        topk_values, topk_indices = torch.topk(similarities, topk, dim=-1)  # [batch_size, n_tokens_A, topk]\n",
        "        result.extend(zip(topk_values, topk_indices))\n",
        "\n",
        "    # Move tensors back to CPU\n",
        "    result = [(values.to('cpu'), indices.to('cpu')) for values, indices in result]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(list_A, list_B, topk=5, batch_size=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    result = []\n",
        "\n",
        "    # Move tensors to GPU\n",
        "    list_A = [tensor.to(device) for tensor in list_A]\n",
        "    list_B = [tensor.to(device) for tensor in list_B]\n",
        "\n",
        "    # Process batch_size tensor_A at a time\n",
        "    for i in tqdm(range(0, len(list_A), batch_size), desc='Processing', dynamic_ncols=True):\n",
        "        batch_A = list_A[i:i+batch_size]\n",
        "        batch_A = torch.nn.utils.rnn.pad_sequence(batch_A, batch_first=True).unsqueeze(2)  # [batch_size, max_n_tokens_A, 1, 768]\n",
        "        similarities = []\n",
        "\n",
        "        for tensor_B in list_B:\n",
        "            tensor_B = tensor_B.unsqueeze(0).unsqueeze(0)  # [1, 1, n_tokens_B, 768]\n",
        "            similarity = torch.nn.functional.cosine_similarity(batch_A, tensor_B, dim=-1)  # [batch_size, max_n_tokens_A, n_tokens_B]\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        similarities = torch.cat(similarities, dim=-1)  # [batch_size, max_n_tokens_A, n_tokens_B*len(list_B)]\n",
        "        topk_values, topk_indices = torch.topk(similarities, topk, dim=-1)  # [batch_size, max_n_tokens_A, topk]\n",
        "        result.extend(zip(topk_values, topk_indices))\n",
        "\n",
        "    # Move tensors back to CPU\n",
        "    result = [(values.to('cpu'), indices.to('cpu')) for values, indices in result]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(list_A, list_B, topk=5, batch_size=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    result = []\n",
        "\n",
        "    # Move list_A tensors to GPU\n",
        "    list_A = [tensor.to(device) for tensor in list_A]\n",
        "\n",
        "    # Process batch_size tensor_A at a time\n",
        "    for i in tqdm(range(0, len(list_A), batch_size), desc='Processing', dynamic_ncols=True):\n",
        "        batch_A = list_A[i:i+batch_size]\n",
        "        batch_A = torch.nn.utils.rnn.pad_sequence(batch_A, batch_first=True).unsqueeze(2)  # [batch_size, max_n_tokens_A, 1, 768]\n",
        "        similarities = []\n",
        "\n",
        "        for tensor_B in list_B:\n",
        "            tensor_B = tensor_B.to(device).unsqueeze(0).unsqueeze(0)  # [1, 1, n_tokens_B, 768]\n",
        "            similarity = torch.nn.functional.cosine_similarity(batch_A, tensor_B, dim=-1)  # [batch_size, max_n_tokens_A, n_tokens_B]\n",
        "            similarities.append(similarity.cpu())  # Move similarity to CPU\n",
        "            del tensor_B  # Delete tensor_B from GPU memory\n",
        "\n",
        "        similarities = torch.cat(similarities, dim=-1)  # [batch_size, max_n_tokens_A, n_tokens_B*len(list_B)]\n",
        "        topk_values, topk_indices = torch.topk(similarities, topk, dim=-1)  # [batch_size, max_n_tokens_A, topk]\n",
        "        result.extend(zip(topk_values, topk_indices))\n",
        "\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "B7c_PajzI_-v"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temp = calculate_cosine_similarity(embeddings_itens[6], embeddings_posts[6])\n",
        "# temp = calculate_cosine_similarity(embeddings_itens[6][0:10], embeddings_posts[6][0:10])\n",
        "\n",
        "embeddings_L6 = calculate_cosine_similarity(embeddings_itens[6], embeddings_posts[6], topk = 10, batch_size=10)\n",
        "\n",
        "\n",
        "len(embeddings_L6)\n",
        "\n",
        "embeddings_L6[0][0]\n",
        "temp[1][0]\n",
        "temp"
      ],
      "metadata": {
        "id": "22Rwhgf_AGFl",
        "outputId": "8f52b61d-e9bc-4d51-ece1-6e167970645a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "         1.0000],\n",
              "        [0.8899, 0.8798, 0.8748, 0.8673, 0.8559, 0.8541, 0.8522, 0.8483, 0.8465,\n",
              "         0.8451],\n",
              "        [0.8344, 0.8274, 0.8268, 0.8252, 0.8208, 0.8167, 0.8166, 0.8138, 0.8114,\n",
              "         0.8090],\n",
              "        [0.8738, 0.8692, 0.8630, 0.8606, 0.8597, 0.8495, 0.8476, 0.8421, 0.8406,\n",
              "         0.8387],\n",
              "        [0.8716, 0.8700, 0.8577, 0.8485, 0.8432, 0.8425, 0.8385, 0.8280, 0.8277,\n",
              "         0.8240],\n",
              "        [0.8677, 0.8470, 0.8469, 0.8409, 0.8336, 0.8275, 0.8259, 0.8203, 0.8199,\n",
              "         0.8158],\n",
              "        [0.8503, 0.8463, 0.8411, 0.8386, 0.8379, 0.8369, 0.8365, 0.8361, 0.8349,\n",
              "         0.8340],\n",
              "        [0.8795, 0.8573, 0.8426, 0.8331, 0.8322, 0.8272, 0.8189, 0.8187, 0.8172,\n",
              "         0.8170],\n",
              "        [0.8749, 0.8705, 0.8654, 0.8611, 0.8589, 0.8553, 0.8551, 0.8523, 0.8508,\n",
              "         0.8484],\n",
              "        [0.8484, 0.8440, 0.8328, 0.8124, 0.8084, 0.8067, 0.8028, 0.8028, 0.7981,\n",
              "         0.7966],\n",
              "        [0.8495, 0.8459, 0.8453, 0.8449, 0.8417, 0.8397, 0.8394, 0.8368, 0.8336,\n",
              "         0.8308],\n",
              "        [0.9111, 0.9042, 0.9032, 0.8995, 0.8937, 0.8929, 0.8925, 0.8919, 0.8911,\n",
              "         0.8908],\n",
              "        [0.9476, 0.9344, 0.9306, 0.9302, 0.9280, 0.9274, 0.9267, 0.9266, 0.9257,\n",
              "         0.9248],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = calculate_cosine_similarity(embeddings_itens[6], embeddings_posts[6])\n",
        "len(embeddings_itens[6][0])\n",
        "len(embeddings_itens[6][1])\n",
        "\n",
        "len(embeddings_posts[6][100])\n",
        "\n",
        "\n",
        "len(temp[511][0])\n",
        "import numpy as np\n",
        "temp[511].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BOQiTNwJCQG",
        "outputId": "e298cadd-d29a-4bb8-f9ed-6d9d002e1da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0060, -0.0287,  0.0209,  ..., -0.0638,  0.0099,  0.0068],\n",
              "        [ 0.8962, -0.1241, -0.5605,  ...,  0.0854, -0.2038, -0.5854],\n",
              "        [ 0.8592, -0.0043, -0.6851,  ..., -0.1660,  0.3144,  0.0245],\n",
              "        ...,\n",
              "        [-0.5750, -0.5947, -1.1486,  ..., -0.0437,  0.1247,  0.2317],\n",
              "        [ 0.1908, -0.5221,  0.1416,  ...,  0.0479, -0.7863, -0.3726],\n",
              "        [-0.3147,  0.5036,  0.3528,  ...,  0.1980,  0.3203,  0.0838]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Save each tuple of (topk_values, topk_indices) in the result\n",
        "for i, (topk_values, topk_indices) in enumerate(embeddings_L6):\n",
        "    np.savez(f'/content/drive/MyDrive/colB5BERT/output_{i}.npz', values=topk_values, indices=topk_indices)\n",
        "\n",
        "data = np.load('output_0.npz')\n",
        "values = data['values']\n",
        "indices = data['indices']\n"
      ],
      "metadata": {
        "id": "zM0a8wbKyGmq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def save_to_csv(tensor_list, filename):\n",
        "    flattened_tensors = [tensor.numpy().flatten() for tensor in tensor_list]\n",
        "    shapes = [tensor.shape for tensor in tensor_list]\n",
        "\n",
        "    data_df = pd.DataFrame({\n",
        "        'tensor': [tensor.tolist() for tensor in flattened_tensors],\n",
        "        'shape': shapes\n",
        "    })\n",
        "\n",
        "    data_df.to_csv(filename, index=False)\n",
        "\n",
        "# Assuming your list of tensors is called tensor_list\n",
        "save_to_csv(embeddings_itens[6], 'embeddings_itens6.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "C9Ut022SSFng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, to compute cosine similarity between tensors, you can use the `torch.nn.functional.cosine_similarity` function provided by PyTorch.\n",
        "\n",
        "Here's a function that computes cosine similarity between every pair of tokens in `A` and `B`, assuming that `A` and `B` are PyTorch tensors.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_cosine_similarity(A, B):\n",
        "    batch_size1, num_of_tokens1, embedding_dim1 = A.shape\n",
        "    batch_size2, num_of_tokens2, embedding_dim2 = B.shape\n",
        "\n",
        "    if embedding_dim1 != embedding_dim2:\n",
        "        raise ValueError(\"Embedding dimensions must match!\")\n",
        "\n",
        "    if batch_size1 != batch_size2:\n",
        "        raise ValueError(\"Batch sizes must match!\")\n",
        "\n",
        "    # We will compute cosine similarity for each example in the batch separately\n",
        "    cosine_similarities = []\n",
        "    for i in range(batch_size1):\n",
        "        a = A[i]\n",
        "        b = B[i]\n",
        "\n",
        "        # Compute cosine similarity between all pairs of tokens.\n",
        "        # The resulting matrix will have shape (num_of_tokens1, num_of_tokens2)\n",
        "        similarity_matrix = torch.zeros((num_of_tokens1, num_of_tokens2))\n",
        "\n",
        "        for j in range(num_of_tokens1):\n",
        "            for k in range(num_of_tokens2):\n",
        "                similarity_matrix[j, k] = F.cosine_similarity(a[j], b[k], dim=0)\n",
        "\n",
        "        cosine_similarities.append(similarity_matrix)\n",
        "\n",
        "    return cosine_similarities\n",
        "```\n",
        "\n",
        "This function will return a list of 2D tensors, each with shape `(num_of_tokens1, num_of_tokens2)`. Each tensor in the list corresponds to an example in the batch. The values in the 2D tensor represent the cosine similarity between the corresponding tokens in `A` and `B`. Note that this is quite a computationally expensive way to compute these similarities due to the nested for loops, and it might be worth looking into more efficient methods if this becomes a bottleneck in your code.\n",
        "\n",
        "Can you do this using vector operations ?\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_cosine_similarity_vectorized(A, B):\n",
        "    # Check for matching dimensions\n",
        "    batch_size1, num_of_tokens1, embedding_dim1 = A.shape\n",
        "    batch_size2, num_of_tokens2, embedding_dim2 = B.shape\n",
        "\n",
        "    if embedding_dim1 != embedding_dim2:\n",
        "        raise ValueError(\"Embedding dimensions must match!\")\n",
        "\n",
        "    if batch_size1 != batch_size2:\n",
        "        raise ValueError(\"Batch sizes must match!\")\n",
        "\n",
        "    A_unsqueezed = A.unsqueeze(2)  # Shape becomes [batch_size, num_of_tokens1, 1, embedding_dim]\n",
        "    B_unsqueezed = B.unsqueeze(1)  # Shape becomes [batch_size, 1, num_of_tokens2, embedding_dim]\n",
        "\n",
        "    # Calculate cosine similarity. The result has shape [batch_size, num_of_tokens1, num_of_tokens2]\n",
        "    similarity_matrix = F.cosine_similarity(A_unsqueezed, B_unsqueezed, dim=-1)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "def get_bert_embeddings(bert_model, examples, layers):\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    bert_model = bert_model.to(device)\n",
        "\n",
        "    embeddings = {layer: [] for layer in layers}\n",
        "    for ex_ids in examples:\n",
        "        # Convert data to tensor and move to GPU\n",
        "        ex_ids_tensor = torch.tensor([ex_ids]).to(device)\n",
        "        with torch.no_grad():\n",
        "            # Output includes 'last_hidden_state', 'pooler_output', 'hidden_states'\n",
        "            output = bert_model(ex_ids_tensor, output_hidden_states=True)\n",
        "            hidden_states = output.hidden_states\n",
        "            for layer in layers:\n",
        "                # Verify layer index is valid\n",
        "                if layer < 0 or layer >= len(hidden_states):\n",
        "                    print(f\"Invalid layer {layer}\")\n",
        "                else:\n",
        "                    # Hidden states is a tuple. Indexing into it gives a tensor of shape\n",
        "                    # (batch_size, sequence_length, hidden_size). Since batch_size is 1,\n",
        "                    # we remove the batch dimension.\n",
        "                    layer_output = hidden_states[layer].squeeze(0)\n",
        "                    # Convert back to CPU for further processing or storage\n",
        "                    embeddings[layer].append(layer_output.to('cpu'))\n",
        "    return embeddings\n",
        "```\n"
      ],
      "metadata": {
        "id": "r0cLFImnZnGW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwNE2XOqGhuV"
      },
      "source": [
        "### Miscelaneous"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python equivalent of R str\n",
        "\n",
        "Yes, there is a similar command in Python called `dir()` which returns a list of all the attributes and methods of any object passed to it¹. Another similar command is `vars()` which returns the __dict__ attribute of an object¹. There is also a function called `inspect.getmembers()` which returns all the members of an object in a list of (name, value) pairs sorted by name¹. I hope this helps!\n",
        "\n",
        "Origem: conversa com o Bing, 05/06/2023\n",
        "(1) Is there a Python equivalent of R's str (), returning only the .... https://stackoverflow.com/questions/27749573/is-there-a-python-equivalent-of-rs-str-returning-only-the-structure-of-an-ob.\n",
        "(2) What are Python pandas equivalents for R functions like str(), summary .... https://stackoverflow.com/questions/27637281/what-are-python-pandas-equivalents-for-r-functions-like-str-summary-and-he.\n",
        "(3) Qual é a diferença entre 'string' e r'string' em Python?. https://pt.stackoverflow.com/questions/80545/qual-%c3%a9-a-diferen%c3%a7a-entre-string-e-rstring-em-python.\n",
        "\n",
        "Understanding complex data structures in Python code often requires carefully examining the code and using built-in Python functions that give insights about these structures. Here are a few steps that might help:\n",
        "\n",
        "1. **Print Statements**: Use `print()` statements liberally to output variables and their types. This can give you an idea of what data structures are being used at various points in the code.\n",
        "\n",
        "2. **Type Checking**: Use the `type()` function to check the type of data structures. For instance, `type(my_var)` would return the type of `my_var`.\n",
        "\n",
        "3. **Introspection**: Use dir() to view the attributes and methods of an object. For example, `dir(my_var)` would list all the methods that can be used with `my_var`.\n",
        "\n",
        "4. **Length and Structure**: Use `len()` to find the length of a data structure. For dictionaries, lists, tuples, etc., you can also print individual elements.\n",
        "\n",
        "5. **Variable Explorer**: If you're using an Integrated Development Environment (IDE) like PyCharm or Jupyter notebook, you can make use of the variable explorer to inspect your variables and data structures.\n",
        "\n",
        "6. **Debugger**: A debugger can help you step through the code one line at a time and examine the changes in your data structures as the code executes. Python's built-in debugger is pdb.\n",
        "\n",
        "7. **Visualization Tools**: For complex data structures like nested dictionaries or dataframes, consider using data visualization tools or libraries like pandas, matplotlib, or seaborn to visualize the data.\n",
        "\n",
        "Remember, understanding complex data structures can be challenging, but it is often a matter of breaking down the structure into smaller, more manageable parts and understanding those individually.\n",
        "\n",
        "In Python, lists and dictionaries don't have dimensions in the way that arrays in NumPy or dataframes in pandas do. Instead, they have lengths, and those lengths can be nested. You can use the built-in `len()` function to find out the number of elements in a list or dictionary.\n",
        "\n",
        "For a list:\n",
        "\n",
        "```python\n",
        "my_list = [1, 2, 3, 4, 5]\n",
        "print(len(my_list))  # Output: 5\n",
        "```\n",
        "\n",
        "For a dictionary:\n",
        "\n",
        "```python\n",
        "my_dict = {'one': 1, 'two': 2, 'three': 3}\n",
        "print(len(my_dict))  # Output: 3\n",
        "```\n",
        "\n",
        "For nested structures, you'd need to use additional `len()` calls or use a loop or comprehension to iterate over the elements.\n",
        "\n",
        "For example, for a list of lists (a 2D list), you could use a list comprehension:\n",
        "\n",
        "```python\n",
        "my_list_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "dimensions = [len(inner_list) for inner_list in my_list_of_lists]\n",
        "print(dimensions)  # Output: [3, 3, 3]\n",
        "```\n",
        "\n",
        "This tells you that you have a \"3x3\" list. Note that this only works for regularly-shaped data; if your lists have differing lengths, you'll get a variety of numbers.\n",
        "\n",
        "For a nested dictionary, things can get more complex, and you may need a recursive function to fully explore the structure if the nesting can be more than one level deep."
      ],
      "metadata": {
        "id": "sc45TpDx-gOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Old functions"
      ],
      "metadata": {
        "id": "xzPeXX_wYX3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_cosine_similarity(list_A, list_B):\n",
        "    result = []\n",
        "    for tensor_A in list_A:\n",
        "        for tensor_B in list_B:\n",
        "            similarity = cosine_similarity(tensor_A.unsqueeze(0), tensor_B.unsqueeze(0), dim=-1)\n",
        "            result.append(similarity)\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(list_A, list_B):\n",
        "    result = []\n",
        "    for tensor_A in list_A:\n",
        "        for tensor_B in list_B:\n",
        "            # Expand dimensions so that shapes are [1, n_tokens_A, 768] and [n_tokens_B, 1, 768]\n",
        "            tensor_A_exp = tensor_A.unsqueeze(0).unsqueeze(1)\n",
        "            tensor_B_exp = tensor_B.unsqueeze(0).unsqueeze(2)\n",
        "\n",
        "            # Repeat tensors so that shapes are [n_tokens_B, n_tokens_A, 768] and [n_tokens_B, n_tokens_A, 768]\n",
        "            tensor_A_rep = tensor_A_exp.repeat(tensor_B.shape[0], 1, 1)\n",
        "            tensor_B_rep = tensor_B_exp.repeat(1, tensor_A.shape[0], 1)\n",
        "            similarity = cosine_similarity(tensor_A_rep, tensor_B_rep, dim=-1)\n",
        "            result.append(similarity)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "SNazzFPSZnvM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qwNE2XOqGhuV"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}